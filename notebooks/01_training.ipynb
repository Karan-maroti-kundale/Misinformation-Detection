{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f845f2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-21 13:09:37.115 No runtime found, using MemoryCacheStorageManager\n",
      "2025-09-21 13:09:37.119 No runtime found, using MemoryCacheStorageManager\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import streamlit as st\n",
    "from PIL import Image, ImageChops, ImageEnhance, ExifTags\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tempfile\n",
    "from dotenv import load_dotenv\n",
    "import tensorflow as tf\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(\"config/.env\")\n",
    "\n",
    "# ------------------------------\n",
    "# Text Model: DistilBERT (TensorFlow-only)\n",
    "# ------------------------------\n",
    "@st.cache_data(ttl=3600)\n",
    "def load_distilbert_model(model_path=\"models/distilbert_fake_news\"):\n",
    "    try:\n",
    "        tokenizer = DistilBertTokenizer.from_pretrained(model_path)\n",
    "        model = TFDistilBertForSequenceClassification.from_pretrained(model_path, from_pt=False)\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "        return tokenizer, model\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error loading DistilBERT TensorFlow model: {e}\")\n",
    "        return None, None\n",
    "\n",
    "@st.cache_data(ttl=1800)\n",
    "def predict_distilbert(text, tokenizer, model):\n",
    "    encodings = tokenizer([text], truncation=True, padding=True, max_length=64, return_tensors=\"tf\")\n",
    "    preds = model(encodings, training=False)\n",
    "    probs = tf.nn.softmax(preds.logits, axis=1).numpy()[0]\n",
    "    label = \"FAKE\" if np.argmax(probs) == 0 else \"TRUE\"\n",
    "    confidence = float(max(probs) * 100)\n",
    "    return label, confidence, probs\n",
    "\n",
    "# ------------------------------\n",
    "# Image Analysis: ELA + Metadata\n",
    "# ------------------------------\n",
    "def error_level_analysis(img: Image.Image, quality=90):\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".jpg\")\n",
    "    img.save(temp_file.name, 'JPEG', quality=quality)\n",
    "    compressed = Image.open(temp_file.name)\n",
    "    ela = ImageChops.difference(img, compressed)\n",
    "    extrema = ela.getextrema()\n",
    "    max_diff = max([ex[1] for ex in extrema])\n",
    "    scale = 255.0 / max_diff if max_diff != 0 else 1\n",
    "    ela = ImageEnhance.Brightness(ela).enhance(scale)\n",
    "    return ela\n",
    "\n",
    "def get_image_metadata(img: Image.Image):\n",
    "    metadata = {}\n",
    "    try:\n",
    "        info = img._getexif()\n",
    "        if info:\n",
    "            for tag, value in info.items():\n",
    "                decoded = ExifTags.TAGS.get(tag, tag)\n",
    "                metadata[decoded] = value\n",
    "    except Exception:\n",
    "        pass\n",
    "    return metadata\n",
    "\n",
    "# ------------------------------\n",
    "# Video Analysis: Keyframes\n",
    "# ------------------------------\n",
    "def extract_keyframes(video_path, threshold=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    success, prev_frame = cap.read()\n",
    "    keyframes = []\n",
    "\n",
    "    while success:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        diff = cv2.absdiff(cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY),\n",
    "                           cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
    "        non_zero_count = np.count_nonzero(diff)\n",
    "        if non_zero_count > threshold:\n",
    "            keyframes.append(frame)\n",
    "        prev_frame = frame\n",
    "    cap.release()\n",
    "    return keyframes\n",
    "\n",
    "# ------------------------------\n",
    "# Streamlit App\n",
    "# ------------------------------\n",
    "st.set_page_config(page_title=\"AI Misinformation Assistant\", page_icon=\"üõ°Ô∏è\", layout=\"wide\")\n",
    "st.title(\"üõ°Ô∏è AI-Powered Misinformation Detection & Literacy Assistant\")\n",
    "\n",
    "# Load model\n",
    "tokenizer, model = load_distilbert_model()\n",
    "MODEL_OK = tokenizer is not None and model is not None\n",
    "\n",
    "st.sidebar.header(\"Model Status\")\n",
    "if MODEL_OK:\n",
    "    st.sidebar.success(\"DistilBERT TensorFlow model loaded ‚úÖ\")\n",
    "else:\n",
    "    st.sidebar.warning(\"DistilBERT model not found. Make sure 'models/distilbert_fake_news' exists.\")\n",
    "\n",
    "# Tabs\n",
    "tab1, tab2, tab3 = st.tabs([\"üìù Text\", \"üñºÔ∏è Image\", \"üé¨ Video\"])\n",
    "\n",
    "# --- Text Tab ---\n",
    "with tab1:\n",
    "    st.subheader(\"Check a piece of text\")\n",
    "    user_text = st.text_area(\"Paste the message / headline here:\", height=160)\n",
    "    if st.button(\"Analyze Text\"):\n",
    "        if not user_text.strip():\n",
    "            st.error(\"Please paste some text.\")\n",
    "        elif MODEL_OK:\n",
    "            label, confidence, probs = predict_distilbert(user_text, tokenizer, model)\n",
    "            st.write(f\"**Prediction:** {label}\")\n",
    "            st.write(f\"**Confidence:** {confidence:.1f}%\")\n",
    "            st.write(f\"**Probabilities:** Fake={probs[0]*100:.1f}%, True={probs[1]*100:.1f}%\")\n",
    "        else:\n",
    "            st.warning(\"Model not loaded.\")\n",
    "\n",
    "# --- Image Tab ---\n",
    "with tab2:\n",
    "    st.subheader(\"Check an image\")\n",
    "    uploaded_file = st.file_uploader(\"Upload an image (jpg/png)\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "    if uploaded_file:\n",
    "        img = Image.open(io.BytesIO(uploaded_file.read())).convert(\"RGB\")\n",
    "        st.image(img, caption=\"Uploaded image\", use_column_width=True)\n",
    "\n",
    "        st.info(\"üîé Running ELA and metadata checks...\")\n",
    "        ela_img = error_level_analysis(img)\n",
    "        st.image(ela_img, caption=\"Error Level Analysis (ELA)\", use_column_width=True)\n",
    "\n",
    "        metadata = get_image_metadata(img)\n",
    "        if metadata:\n",
    "            st.write(\"Metadata found:\")\n",
    "            st.json(metadata)\n",
    "        else:\n",
    "            st.info(\"No metadata found.\")\n",
    "\n",
    "# --- Video Tab ---\n",
    "with tab3:\n",
    "    st.subheader(\"Check a video\")\n",
    "    uploaded_video = st.file_uploader(\"Upload a video (mp4)\", type=[\"mp4\"])\n",
    "    if uploaded_video:\n",
    "        temp_video = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\")\n",
    "        temp_video.write(uploaded_video.read())\n",
    "        st.video(temp_video.name)\n",
    "\n",
    "        st.info(\"üîé Extracting keyframes...\")\n",
    "        keyframes = extract_keyframes(temp_video.name)\n",
    "        st.write(f\"Number of keyframes detected: {len(keyframes)}\")\n",
    "        if keyframes:\n",
    "            st.image([cv2.cvtColor(f, cv2.COLOR_BGR2RGB) for f in keyframes[:5]],\n",
    "                     caption=[f\"Keyframe {i+1}\" for i in range(min(5, len(keyframes)))],\n",
    "                     width=200)\n",
    "\n",
    "st.caption(\"Educational starter. Always verify with trusted sources.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "760621cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
